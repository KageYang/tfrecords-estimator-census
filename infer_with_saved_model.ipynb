{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/1544257357/variables/variables\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir= \"./saved_model/1544257357\"\n",
    "predict_fn = predictor.from_saved_model(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_func(s_example):\n",
    "    features = {\n",
    "                'workclass': tf.FixedLenFeature((), tf.string),\n",
    "                'sex': tf.FixedLenFeature((), tf.string),\n",
    "                'age': tf.FixedLenFeature((), tf.int64),\n",
    "                'education': tf.FixedLenFeature((), tf.string),\n",
    "                'education-num': tf.FixedLenFeature((), tf.int64),\n",
    "                'marital-status': tf.FixedLenFeature((), tf.string),\n",
    "                'occupation': tf.FixedLenFeature((), tf.string),\n",
    "                'hours-per-week': tf.FixedLenFeature((), tf.int64),\n",
    "                'label': tf.FixedLenFeature((), tf.string)\n",
    "                 }\n",
    "    return tf.parse_single_example(s_example, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= tf.data.TFRecordDataset('census_test.tfrecord').batch(3)\n",
    "next_batch= data.make_one_shot_iterator().get_next()\n",
    "sess= tf.Session() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read batches of serialized examples from `tfrecord` and feed them to predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64114726 0.35885268]\n",
      " [0.44513756 0.55486244]\n",
      " [0.67866397 0.3213361 ]] [b' <=50K.', b' <=50K.', b' >50K.']\n"
     ]
    }
   ],
   "source": [
    "examples = sess.run(next_batch)\n",
    "predictions = predict_fn({'inputs':examples})\n",
    "\n",
    "print(predictions['scores'],[sess.run(parse_func(example))['label'] for example in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': array([[b'0', b'1'],\n",
       "        [b'0', b'1'],\n",
       "        [b'0', b'1']], dtype=object),\n",
       " 'scores': array([[0.64114726, 0.35885268],\n",
       "        [0.44513756, 0.55486244],\n",
       "        [0.67866397, 0.3213361 ]], dtype=float32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect saved model meta data with `saved_model_cli show`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import saved_model_cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['classification']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['inputs'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: input_example_tensor:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['classes'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 2)\n",
      "        name: head/Tile:0\n",
      "    outputs['scores'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 2)\n",
      "        name: head/predictions/probabilities:0\n",
      "  Method name is: tensorflow/serving/classify\n",
      "\n",
      "signature_def['predict']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['examples'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: input_example_tensor:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['class_ids'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 1)\n",
      "        name: head/predictions/ExpandDims:0\n",
      "    outputs['classes'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 1)\n",
      "        name: head/predictions/str_classes:0\n",
      "    outputs['logistic'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: head/predictions/logistic:0\n",
      "    outputs['logits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: add:0\n",
      "    outputs['probabilities'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 2)\n",
      "        name: head/predictions/probabilities:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "signature_def['regression']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['inputs'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: input_example_tensor:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['outputs'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: head/predictions/logistic:0\n",
      "  Method name is: tensorflow/serving/regress\n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['inputs'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1)\n",
      "        name: input_example_tensor:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['classes'] tensor_info:\n",
      "        dtype: DT_STRING\n",
      "        shape: (-1, 2)\n",
      "        name: head/Tile:0\n",
      "    outputs['scores'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 2)\n",
      "        name: head/predictions/probabilities:0\n",
      "  Method name is: tensorflow/serving/classify\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir saved_model/1544257357 --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `saved_model_cli run` to make inference against saved model (`predict` Signature)\n",
    "#### First, save the batch of examples to `.npy` file\n",
    "#### Then, use `saved_model_cli` to run the model by reading inputs from `.npy` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('examples.npy',examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-02 07:01:02.453741: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "Result for output key class_ids:\n",
      "[[0]\n",
      " [1]\n",
      " [0]]\n",
      "Result for output key classes:\n",
      "[[b'0']\n",
      " [b'1']\n",
      " [b'0']]\n",
      "Result for output key logistic:\n",
      "[[0.35885268]\n",
      " [0.55486244]\n",
      " [0.32133606]]\n",
      "Result for output key logits:\n",
      "[[-0.5803472 ]\n",
      " [ 0.22033691]\n",
      " [-0.7476385 ]]\n",
      "Result for output key probabilities:\n",
      "[[0.64114726 0.35885268]\n",
      " [0.44513756 0.55486244]\n",
      " [0.67866397 0.3213361 ]]\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli run --dir saved_model/1544257357 \\\n",
    " --tag_set serve --signature_def predict \\\n",
    " --inputs examples=examples.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send inference request to the model serviced by tensorflow model server over REST api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'CoEDChQKBWxhYmVsEgsKCQoHIDw9NTBLLgoMCgNhZ2USBRoDCgEZChYKCWVkdWNhdGlvbhIJCgcKBSAxMXRoChcKDmhvdXJzLXBlci13ZWVrEgUaAwoBKAoQCgNzZXgSCQoHCgUgTWFsZQoeCgxyZWxhdGlvbnNoaXASDgoMCgogT3duLWNoaWxkChUKDGNhcGl0YWwtZ2FpbhIFGgMKAQAKJAoObmF0aXZlLWNvdW50cnkSEgoQCg4gVW5pdGVkLVN0YXRlcwokCgpvY2N1cGF0aW9uEhYKFAoSIE1hY2hpbmUtb3AtaW5zcGN0ChYKDWVkdWNhdGlvbi1udW0SBRoDCgEHCiQKDm1hcml0YWwtc3RhdHVzEhIKEAoOIE5ldmVyLW1hcnJpZWQKFQoMY2FwaXRhbC1sb3NzEgUaAwoBAAoSCgRyYWNlEgoKCAoGIEJsYWNrChkKCXdvcmtjbGFzcxIMCgoKCCBQcml2YXRlChEKBmZubHdndBIHGgUKA/LrDQ==',\n",
       "       b'CoUDChwKDHJlbGF0aW9uc2hpcBIMCgoKCCBIdXNiYW5kChUKDGNhcGl0YWwtZ2FpbhIFGgMKAQAKJAoObmF0aXZlLWNvdW50cnkSEgoQCg4gVW5pdGVkLVN0YXRlcwoiCgpvY2N1cGF0aW9uEhQKEgoQIEZhcm1pbmctZmlzaGluZwoWCg1lZHVjYXRpb24tbnVtEgUaAwoBCQopCg5tYXJpdGFsLXN0YXR1cxIXChUKEyBNYXJyaWVkLWNpdi1zcG91c2UKFQoMY2FwaXRhbC1sb3NzEgUaAwoBAAoSCgRyYWNlEgoKCAoGIFdoaXRlChkKCXdvcmtjbGFzcxIMCgoKCCBQcml2YXRlChEKBmZubHdndBIHGgUKA9a9BQoUCgVsYWJlbBILCgkKByA8PTUwSy4KDAoDYWdlEgUaAwoBJgoZCgllZHVjYXRpb24SDAoKCgggSFMtZ3JhZAoXCg5ob3Vycy1wZXItd2VlaxIFGgMKATIKEAoDc2V4EgkKBwoFIE1hbGU=',\n",
       "       b'CokDChwKCWVkdWNhdGlvbhIPCg0KCyBBc3NvYy1hY2RtChcKDmhvdXJzLXBlci13ZWVrEgUaAwoBKAoQCgNzZXgSCQoHCgUgTWFsZQocCgxyZWxhdGlvbnNoaXASDAoKCgggSHVzYmFuZAoVCgxjYXBpdGFsLWdhaW4SBRoDCgEACiQKDm5hdGl2ZS1jb3VudHJ5EhIKEAoOIFVuaXRlZC1TdGF0ZXMKIgoKb2NjdXBhdGlvbhIUChIKECBQcm90ZWN0aXZlLXNlcnYKFgoNZWR1Y2F0aW9uLW51bRIFGgMKAQwKKQoObWFyaXRhbC1zdGF0dXMSFwoVChMgTWFycmllZC1jaXYtc3BvdXNlChUKDGNhcGl0YWwtbG9zcxIFGgMKAQAKEgoEcmFjZRIKCggKBiBXaGl0ZQobCgl3b3JrY2xhc3MSDgoMCgogTG9jYWwtZ292ChEKBmZubHdndBIHGgUKA7fIFAoTCgVsYWJlbBIKCggKBiA+NTBLLgoMCgNhZ2USBRoDCgEc'],\n",
       "      dtype='|S528')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "encoded = np.array([base64.b64encode(example) for example in examples])\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'CoEDChQKBWxhYmVsEgsKCQoHIDw9NTBLLgoMCgNhZ2USBRoDCgEZChYKCWVkdWNhdGlvbhIJCgcKBSAxMXRoChcKDmhvdXJzLXBlci13ZWVrEgUaAwoBKAoQCgNzZXgSCQoHCgUgTWFsZQoeCgxyZWxhdGlvbnNoaXASDgoMCgogT3duLWNoaWxkChUKDGNhcGl0YWwtZ2FpbhIFGgMKAQAKJAoObmF0aXZlLWNvdW50cnkSEgoQCg4gVW5pdGVkLVN0YXRlcwokCgpvY2N1cGF0aW9uEhYKFAoSIE1hY2hpbmUtb3AtaW5zcGN0ChYKDWVkdWNhdGlvbi1udW0SBRoDCgEHCiQKDm1hcml0YWwtc3RhdHVzEhIKEAoOIE5ldmVyLW1hcnJpZWQKFQoMY2FwaXRhbC1sb3NzEgUaAwoBAAoSCgRyYWNlEgoKCAoGIEJsYWNrChkKCXdvcmtjbGFzcxIMCgoKCCBQcml2YXRlChEKBmZubHdndBIHGgUKA/LrDQ=='"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `post_msg` , a file whose JSON formated contents are part of inference request to be sent over REST api.  The binary bytes (ex: serialization of structured data)  have to be Base64 encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "\"signature_name\": \"predict\",\r\n",
      "\"inputs\":[\r\n",
      "{\"b64\":\"CoEDChQKBWxhYmVsEgsKCQoHIDw9NTBLLgoMCgNhZ2USBRoDCgEZChYKCWVkdWNhdGlvbhIJCgcKBSAxMXRoChcKDmhvdXJzLXBlci13ZWVrEgUaAwoBKAoQCgNzZXgSCQoHCgUgTWFsZQoeCgxyZWxhdGlvbnNoaXASDgoMCgogT3duLWNoaWxkChUKDGNhcGl0YWwtZ2FpbhIFGgMKAQAKJAoObmF0aXZlLWNvdW50cnkSEgoQCg4gVW5pdGVkLVN0YXRlcwokCgpvY2N1cGF0aW9uEhYKFAoSIE1hY2hpbmUtb3AtaW5zcGN0ChYKDWVkdWNhdGlvbi1udW0SBRoDCgEHCiQKDm1hcml0YWwtc3RhdHVzEhIKEAoOIE5ldmVyLW1hcnJpZWQKFQoMY2FwaXRhbC1sb3NzEgUaAwoBAAoSCgRyYWNlEgoKCAoGIEJsYWNrChkKCXdvcmtjbGFzcxIMCgoKCCBQcml2YXRlChEKBmZubHdndBIHGgUKA/LrDQ==\"},\r\n",
      "{\"b64\":\"CoUDChwKDHJlbGF0aW9uc2hpcBIMCgoKCCBIdXNiYW5kChUKDGNhcGl0YWwtZ2FpbhIFGgMKAQAKJAoObmF0aXZlLWNvdW50cnkSEgoQCg4gVW5pdGVkLVN0YXRlcwoiCgpvY2N1cGF0aW9uEhQKEgoQIEZhcm1pbmctZmlzaGluZwoWCg1lZHVjYXRpb24tbnVtEgUaAwoBCQopCg5tYXJpdGFsLXN0YXR1cxIXChUKEyBNYXJyaWVkLWNpdi1zcG91c2UKFQoMY2FwaXRhbC1sb3NzEgUaAwoBAAoSCgRyYWNlEgoKCAoGIFdoaXRlChkKCXdvcmtjbGFzcxIMCgoKCCBQcml2YXRlChEKBmZubHdndBIHGgUKA9a9BQoUCgVsYWJlbBILCgkKByA8PTUwSy4KDAoDYWdlEgUaAwoBJgoZCgllZHVjYXRpb24SDAoKCgggSFMtZ3JhZAoXCg5ob3Vycy1wZXItd2VlaxIFGgMKATIKEAoDc2V4EgkKBwoFIE1hbGU=\"},\r\n",
      "{\"b64\":\"CokDChwKCWVkdWNhdGlvbhIPCg0KCyBBc3NvYy1hY2RtChcKDmhvdXJzLXBlci13ZWVrEgUaAwoBKAoQCgNzZXgSCQoHCgUgTWFsZQocCgxyZWxhdGlvbnNoaXASDAoKCgggSHVzYmFuZAoVCgxjYXBpdGFsLWdhaW4SBRoDCgEACiQKDm5hdGl2ZS1jb3VudHJ5EhIKEAoOIFVuaXRlZC1TdGF0ZXMKIgoKb2NjdXBhdGlvbhIUChIKECBQcm90ZWN0aXZlLXNlcnYKFgoNZWR1Y2F0aW9uLW51bRIFGgMKAQwKKQoObWFyaXRhbC1zdGF0dXMSFwoVChMgTWFycmllZC1jaXYtc3BvdXNlChUKDGNhcGl0YWwtbG9zcxIFGgMKAQAKEgoEcmFjZRIKCggKBiBXaGl0ZQobCgl3b3JrY2xhc3MSDgoMCgogTG9jYWwtZ292ChEKBmZubHdndBIHGgUKA7fIFAoTCgVsYWJlbBIKCggKBiA+NTBLLgoMCgNhZ2USBRoDCgEc\"}\r\n",
      "]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat post_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `curl` to send inference request to the model serviced by tensorflow model server over REST api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"outputs\": {\r\n",
      "        \"logistic\": [\r\n",
      "            [\r\n",
      "                0.358853\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0.554862\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0.321336\r\n",
      "            ]\r\n",
      "        ],\r\n",
      "        \"class_ids\": [\r\n",
      "            [\r\n",
      "                0\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                1\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0\r\n",
      "            ]\r\n",
      "        ],\r\n",
      "        \"probabilities\": [\r\n",
      "            [\r\n",
      "                0.641147,\r\n",
      "                0.358853\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0.445138,\r\n",
      "                0.554862\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0.678664,\r\n",
      "                0.321336\r\n",
      "            ]\r\n",
      "        ],\r\n",
      "        \"classes\": [\r\n",
      "            [\r\n",
      "                \"0\"\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                \"1\"\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                \"0\"\r\n",
      "            ]\r\n",
      "        ],\r\n",
      "        \"logits\": [\r\n",
      "            [\r\n",
      "                -0.580347\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0.220337\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                -0.747639\r\n",
      "            ]\r\n",
      "        ]\r\n",
      "    }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!curl -d @post_msg -X POST http://tfserving:8501/v1/models/census:predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (7) Failed to connect to localhost port 8501: Connection refused\r\n"
     ]
    }
   ],
   "source": [
    "!curl -d @post_msg -X POST http://localhost:8501/v1/models/census:predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/tmp/census\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
