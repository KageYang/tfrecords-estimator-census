{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/1544257357/variables/variables\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir= \"./saved_model/1544257357\"\n",
    "predict_fn = predictor.from_saved_model(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_func(s_example):\n",
    "    features = {\n",
    "                'workclass': tf.FixedLenFeature((), tf.string),\n",
    "                'sex': tf.FixedLenFeature((), tf.string),\n",
    "                'age': tf.FixedLenFeature((), tf.int64),\n",
    "                'education': tf.FixedLenFeature((), tf.string),\n",
    "                'education-num': tf.FixedLenFeature((), tf.int64),\n",
    "                'marital-status': tf.FixedLenFeature((), tf.string),\n",
    "                'occupation': tf.FixedLenFeature((), tf.string),\n",
    "                'hours-per-week': tf.FixedLenFeature((), tf.int64),\n",
    "                'label': tf.FixedLenFeature((), tf.string)\n",
    "                 }\n",
    "    return tf.parse_single_example(s_example, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= tf.data.TFRecordDataset('census_test.tfrecord').batch(3)\n",
    "next_batch= data.make_one_shot_iterator().get_next()\n",
    "sess= tf.Session() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read batches of serialized examples from `tfrecord` and feed them to predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8598315  0.14016849]\n",
      " [0.19413778 0.8058622 ]\n",
      " [0.384946   0.6150541 ]] [b' <=50K.', b' >50K.', b' <=50K.']\n"
     ]
    }
   ],
   "source": [
    "examples = sess.run(next_batch)\n",
    "predictions = predict_fn({'inputs':examples})\n",
    "\n",
    "print(predictions['scores'],[sess.run(parse_func(example))['label'] for example in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scores': array([[0.64114726, 0.35885268],\n",
       "        [0.44513756, 0.55486244],\n",
       "        [0.67866397, 0.3213361 ]], dtype=float32),\n",
       " 'classes': array([[b'0', b'1'],\n",
       "        [b'0', b'1'],\n",
       "        [b'0', b'1']], dtype=object)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect saved model meta data with `saved_model_cli show`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import saved_model_cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\r\n",
      "SignatureDef key: \"classification\"\r\n",
      "SignatureDef key: \"predict\"\r\n",
      "SignatureDef key: \"regression\"\r\n",
      "SignatureDef key: \"serving_default\"\r\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir saved_model/1544257357 --tag_set serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `saved_model_cli run` to make inference against saved model (`predict` Signature)\n",
    "#### First, save the batch of examples to `.npy` file\n",
    "#### Then, use `saved_model_cli` to run the model by reading inputs from `.npy` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('examples.npy',examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-09 23:47:05.260278: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "Result for output key class_ids:\n",
      "[[0]\n",
      " [1]\n",
      " [1]]\n",
      "Result for output key classes:\n",
      "[[b'0']\n",
      " [b'1']\n",
      " [b'1']]\n",
      "Result for output key logistic:\n",
      "[[0.14016849]\n",
      " [0.8058622 ]\n",
      " [0.6150541 ]]\n",
      "Result for output key logits:\n",
      "[[-1.8138913]\n",
      " [ 1.4233446]\n",
      " [ 0.4686072]]\n",
      "Result for output key probabilities:\n",
      "[[0.8598315  0.14016849]\n",
      " [0.19413778 0.8058622 ]\n",
      " [0.384946   0.6150541 ]]\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli run --dir saved_model/1544257357 \\\n",
    " --tag_set serve --signature_def predict \\\n",
    " --inputs examples=examples.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send inference request to the model serviced by tensorflow model server over REST api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'CoIDChEKBmZubHdndBIHGgUKA6S0BgoUCgVsYWJlbBILCgkKByA8PTUwSy4KDAoDYWdlEgUaAwoBNwoZCgllZHVjYXRpb24SDAoKCgggN3RoLTh0aAoXCg5ob3Vycy1wZXItd2VlaxIFGgMKAQoKEAoDc2V4EgkKBwoFIE1hbGUKHAoMcmVsYXRpb25zaGlwEgwKCgoIIEh1c2JhbmQKFQoMY2FwaXRhbC1nYWluEgUaAwoBAAokCg5uYXRpdmUtY291bnRyeRISChAKDiBVbml0ZWQtU3RhdGVzCh8KCm9jY3VwYXRpb24SEQoPCg0gQ3JhZnQtcmVwYWlyChYKDWVkdWNhdGlvbi1udW0SBRoDCgEECikKDm1hcml0YWwtc3RhdHVzEhcKFQoTIE1hcnJpZWQtY2l2LXNwb3VzZQoVCgxjYXBpdGFsLWxvc3MSBRoDCgEAChIKBHJhY2USCgoICgYgV2hpdGUKGQoJd29ya2NsYXNzEgwKCgoIIFByaXZhdGU=',\n",
       "       b'CocDChAKA3NleBIJCgcKBSBNYWxlChwKDHJlbGF0aW9uc2hpcBIMCgoKCCBIdXNiYW5kChYKDGNhcGl0YWwtZ2FpbhIGGgQKApIyCiQKDm5hdGl2ZS1jb3VudHJ5EhIKEAoOIFVuaXRlZC1TdGF0ZXMKJAoKb2NjdXBhdGlvbhIWChQKEiBNYWNoaW5lLW9wLWluc3BjdAoWCg1lZHVjYXRpb24tbnVtEgUaAwoBCQopCg5tYXJpdGFsLXN0YXR1cxIXChUKEyBNYXJyaWVkLWNpdi1zcG91c2UKFQoMY2FwaXRhbC1sb3NzEgUaAwoBAAoSCgRyYWNlEgoKCAoGIFdoaXRlChkKCXdvcmtjbGFzcxIMCgoKCCBQcml2YXRlChEKBmZubHdndBIHGgUKA4ahCwoTCgVsYWJlbBIKCggKBiA+NTBLLgoMCgNhZ2USBRoDCgFBChkKCWVkdWNhdGlvbhIMCgoKCCBIUy1ncmFkChcKDmhvdXJzLXBlci13ZWVrEgUaAwoBKA==',\n",
       "       b'CogDChAKA3NleBIJCgcKBSBNYWxlChwKDHJlbGF0aW9uc2hpcBIMCgoKCCBIdXNiYW5kChUKDGNhcGl0YWwtZ2FpbhIFGgMKAQAKJAoObmF0aXZlLWNvdW50cnkSEgoQCg4gVW5pdGVkLVN0YXRlcwofCgpvY2N1cGF0aW9uEhEKDwoNIEFkbS1jbGVyaWNhbAoWCg1lZHVjYXRpb24tbnVtEgUaAwoBDQopCg5tYXJpdGFsLXN0YXR1cxIXChUKEyBNYXJyaWVkLWNpdi1zcG91c2UKFQoMY2FwaXRhbC1sb3NzEgUaAwoBAAoSCgRyYWNlEgoKCAoGIFdoaXRlCh0KCXdvcmtjbGFzcxIQCg4KDCBGZWRlcmFsLWdvdgoRCgZmbmx3Z3QSBxoFCgPx+wwKFAoFbGFiZWwSCwoJCgcgPD01MEsuCgwKA2FnZRIFGgMKASQKGwoJZWR1Y2F0aW9uEg4KDAoKIEJhY2hlbG9ycwoXCg5ob3Vycy1wZXItd2VlaxIFGgMKASg='],\n",
       "      dtype='|S528')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "encoded = np.array([base64.b64encode(example) for example in examples])\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'CoIDChEKBmZubHdndBIHGgUKA6S0BgoUCgVsYWJlbBILCgkKByA8PTUwSy4KDAoDYWdlEgUaAwoBNwoZCgllZHVjYXRpb24SDAoKCgggN3RoLTh0aAoXCg5ob3Vycy1wZXItd2VlaxIFGgMKAQoKEAoDc2V4EgkKBwoFIE1hbGUKHAoMcmVsYXRpb25zaGlwEgwKCgoIIEh1c2JhbmQKFQoMY2FwaXRhbC1nYWluEgUaAwoBAAokCg5uYXRpdmUtY291bnRyeRISChAKDiBVbml0ZWQtU3RhdGVzCh8KCm9jY3VwYXRpb24SEQoPCg0gQ3JhZnQtcmVwYWlyChYKDWVkdWNhdGlvbi1udW0SBRoDCgEECikKDm1hcml0YWwtc3RhdHVzEhcKFQoTIE1hcnJpZWQtY2l2LXNwb3VzZQoVCgxjYXBpdGFsLWxvc3MSBRoDCgEAChIKBHJhY2USCgoICgYgV2hpdGUKGQoJd29ya2NsYXNzEgwKCgoIIFByaXZhdGU='"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `post_msg` , a file whose JSON formated contents are part of inference request to be sent over REST api.  The binary bytes (ex: serialization of structured data)  have to be Base64 encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "\"signature_name\": \"predict\",\r\n",
      "\"inputs\":[\r\n",
      "{\"b64\":\"CoEDChQKBWxhYmVsEgsKCQoHIDw9NTBLLgoMCgNhZ2USBRoDCgEZChYKCWVkdWNhdGlvbhIJCgcKBSAxMXRoChcKDmhvdXJzLXBlci13ZWVrEgUaAwoBKAoQCgNzZXgSCQoHCgUgTWFsZQoeCgxyZWxhdGlvbnNoaXASDgoMCgogT3duLWNoaWxkChUKDGNhcGl0YWwtZ2FpbhIFGgMKAQAKJAoObmF0aXZlLWNvdW50cnkSEgoQCg4gVW5pdGVkLVN0YXRlcwokCgpvY2N1cGF0aW9uEhYKFAoSIE1hY2hpbmUtb3AtaW5zcGN0ChYKDWVkdWNhdGlvbi1udW0SBRoDCgEHCiQKDm1hcml0YWwtc3RhdHVzEhIKEAoOIE5ldmVyLW1hcnJpZWQKFQoMY2FwaXRhbC1sb3NzEgUaAwoBAAoSCgRyYWNlEgoKCAoGIEJsYWNrChkKCXdvcmtjbGFzcxIMCgoKCCBQcml2YXRlChEKBmZubHdndBIHGgUKA/LrDQ==\"},\r\n",
      "{\"b64\":\"CoUDChwKDHJlbGF0aW9uc2hpcBIMCgoKCCBIdXNiYW5kChUKDGNhcGl0YWwtZ2FpbhIFGgMKAQAKJAoObmF0aXZlLWNvdW50cnkSEgoQCg4gVW5pdGVkLVN0YXRlcwoiCgpvY2N1cGF0aW9uEhQKEgoQIEZhcm1pbmctZmlzaGluZwoWCg1lZHVjYXRpb24tbnVtEgUaAwoBCQopCg5tYXJpdGFsLXN0YXR1cxIXChUKEyBNYXJyaWVkLWNpdi1zcG91c2UKFQoMY2FwaXRhbC1sb3NzEgUaAwoBAAoSCgRyYWNlEgoKCAoGIFdoaXRlChkKCXdvcmtjbGFzcxIMCgoKCCBQcml2YXRlChEKBmZubHdndBIHGgUKA9a9BQoUCgVsYWJlbBILCgkKByA8PTUwSy4KDAoDYWdlEgUaAwoBJgoZCgllZHVjYXRpb24SDAoKCgggSFMtZ3JhZAoXCg5ob3Vycy1wZXItd2VlaxIFGgMKATIKEAoDc2V4EgkKBwoFIE1hbGU=\"},\r\n",
      "{\"b64\":\"CokDChwKCWVkdWNhdGlvbhIPCg0KCyBBc3NvYy1hY2RtChcKDmhvdXJzLXBlci13ZWVrEgUaAwoBKAoQCgNzZXgSCQoHCgUgTWFsZQocCgxyZWxhdGlvbnNoaXASDAoKCgggSHVzYmFuZAoVCgxjYXBpdGFsLWdhaW4SBRoDCgEACiQKDm5hdGl2ZS1jb3VudHJ5EhIKEAoOIFVuaXRlZC1TdGF0ZXMKIgoKb2NjdXBhdGlvbhIUChIKECBQcm90ZWN0aXZlLXNlcnYKFgoNZWR1Y2F0aW9uLW51bRIFGgMKAQwKKQoObWFyaXRhbC1zdGF0dXMSFwoVChMgTWFycmllZC1jaXYtc3BvdXNlChUKDGNhcGl0YWwtbG9zcxIFGgMKAQAKEgoEcmFjZRIKCggKBiBXaGl0ZQobCgl3b3JrY2xhc3MSDgoMCgogTG9jYWwtZ292ChEKBmZubHdndBIHGgUKA7fIFAoTCgVsYWJlbBIKCggKBiA+NTBLLgoMCgNhZ2USBRoDCgEc\"}\r\n",
      "]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat post_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `curl` to send inference request to the model serviced by tensorflow model server over REST api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"outputs\": {\r\n",
      "        \"class_ids\": [\r\n",
      "            [\r\n",
      "                0\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                1\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0\r\n",
      "            ]\r\n",
      "        ],\r\n",
      "        \"probabilities\": [\r\n",
      "            [\r\n",
      "                0.641147,\r\n",
      "                0.358853\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0.445138,\r\n",
      "                0.554862\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0.678664,\r\n",
      "                0.321336\r\n",
      "            ]\r\n",
      "        ],\r\n",
      "        \"classes\": [\r\n",
      "            [\r\n",
      "                \"0\"\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                \"1\"\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                \"0\"\r\n",
      "            ]\r\n",
      "        ],\r\n",
      "        \"logits\": [\r\n",
      "            [\r\n",
      "                -0.580347\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0.220337\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                -0.747639\r\n",
      "            ]\r\n",
      "        ],\r\n",
      "        \"logistic\": [\r\n",
      "            [\r\n",
      "                0.358853\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0.554862\r\n",
      "            ],\r\n",
      "            [\r\n",
      "                0.321336\r\n",
      "            ]\r\n",
      "        ]\r\n",
      "    }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!curl -d @post_msg -X POST http://localhost:8501/v1/models/census:predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
